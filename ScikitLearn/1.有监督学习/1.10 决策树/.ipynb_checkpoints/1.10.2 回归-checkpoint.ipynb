{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37471c5d-99f6-4287-a8c3-42c9677513db",
   "metadata": {},
   "source": [
    "DecisionTreeRegressor 是 scikit-learn 中用于回归任务的决策树模型，其参数与分类树（DecisionTreeClassifier）有许多相似之处，但也存在一些关键差异。以下是核心参数及其作用：\n",
    "### 1. 控制树结构的参数\n",
    "|参数\t|作用\t|默认值|\n",
    "| ---- | ---- | ---- |\n",
    "|criterion\t|分裂质量的衡量标准，可选：<br>- mse（均方误差，最常用）<br>- friedman_mse（改进的均方误差）<br>- mae（平均绝对误差）\t|mse|\n",
    "|splitter\t|分裂策略，可选：<br>- best（选择最优分裂点）<br>- random（随机选择分裂点，增加随机性）|\tbest|\n",
    "|max_depth\t|树的最大深度。若为 None，则节点会一直分裂直到所有叶子节点都是纯的，或达到最小样本数限制。\t|None\n",
    "|min_samples_split\t|分裂内部节点所需的最小样本数。可以是整数或浮点数（百分比）。\t|2|\n",
    "|min_samples_leaf\t|叶子节点所需的最小样本数。可以是整数或浮点数（百分比）。\t|1|\n",
    "|min_weight_fraction_leaf\t|叶子节点所需的最小权重总和（针对样本权重）。\t|0.0|\n",
    "|max_features\t|寻找最佳分裂时考虑的特征数量。可选：<br>- 整数、浮点数、auto（即 n_features）、sqrt、log2、None（使用所有特征）\t|None|\n",
    "|max_leaf_nodes\t|最大叶子节点数。若为 None，则无限制。\t|None|\n",
    "|min_impurity_decrease\t|分裂所需的最小不纯度减少量。若分裂导致的不纯度减少小于该值，则不分裂。\t|0.0|\n",
    "\n",
    "### 2. 处理缺失值和样本权重的参数\n",
    "|参数\t|作用\t|默认值|\n",
    "| ---- | ---- | ---- |\n",
    "|missing_values\t|识别缺失值的标记（仅在 scikit-learn 1.2+ 支持）。例如 np.nan。\t|np.nan|\n",
    "|ccp_alpha\t|成本复杂度剪枝参数。较大的值会导致更多剪枝，生成更简单的树。\t|0.0|\n",
    "|random_state\t|随机数种子，控制随机性（如特征选择的随机性）。\tNone\n",
    "|class_weight\t|样本权重，用于处理不平衡数据。回归任务中通常不需要（默认 None）。\t|None|\n",
    "\n",
    "### 3. 其他参数\n",
    "|参数\t|作用\t|默认值|\n",
    "| ---- | ---- | ---- |\n",
    "|presort\t|是否预排序数据以加速寻找最佳分裂点。在大数据集上可能降低效率。\t|deprecated|\n",
    "|min_impurity_split\t|提前停止分裂的不纯度阈值（已弃用，改用 min_impurity_decrease）。\t|-|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ce20c-623b-44d0-a19d-99368e019303",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor 核心方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b25ce3-f23f-43c7-8e2d-0ae0408fdf48",
   "metadata": {},
   "source": [
    "### 1. 模型训练与预测\n",
    "|方法\t|作用|\n",
    "| ---- | ---- |\n",
    "|fit(X, y[, sample_weight, check_input])\t训练模型。<br>- X: 特征矩阵<br>- y: 目标值（连续值）<br>- sample_weight: 样本权重|\n",
    "|predict(X[, check_input])\t|对输入数据进行预测，返回预测值。|\n",
    "|predict_log_proba(X)\t|对输入数据预测对数概率密度（仅在支持概率输出的回归器中可用）。|\n",
    "|score(X, y[, sample_weight])\t|返回预测的 R² 分数（决定系数），评估模型拟合优度。|\n",
    "\n",
    "### 2. 树结构与特征分析\n",
    "|方法\t|作用|\n",
    "| ---- | ---- |\n",
    "|get_depth()\t|返回决策树的深度（即根节点到最远叶子节点的路径长度）。|\n",
    "|get_n_leaves()\t|返回决策树的叶子节点数量。|\n",
    "|feature_importances_\t|返回特征重要性得分（值越高，特征越重要）。|\n",
    "|tree_\t|返回底层的树对象，包含详细的树结构信息（如节点分裂规则、叶子节点值）。|\n",
    "\n",
    "### 3. 模型保存与加载\n",
    "|方法\t|作用|\n",
    "| ---- | ---- |\n",
    "|__getstate__()\t|返回模型的状态（用于序列化）。|\n",
    "|__setstate__(state)\t|从状态恢复模型（用于反序列化）。|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21a51d-4ee9-4f6c-94db-2e189596e77f",
   "metadata": {},
   "source": [
    "## 决策树回归与分类的关键差异\n",
    "|对比项\t|决策树回归（DecisionTreeRegressor）\t|决策树分类（DecisionTreeClassifier）|\n",
    "| ---- | ---- | ---- |\n",
    "|目标变量类型\t|连续值（如房价、温度）\t|离散类别（如猫 / 狗、垃圾邮件 / 正常邮件）|\n",
    "|默认分裂标准\t|mse（均方误差）\t|gini（基尼不纯度）或 entropy（信息熵）|\n",
    "|叶子节点值\t|该节点样本的平均值\t|该节点样本中最多的类别|\n",
    "|评估指标\t|R²、MSE、MAE 等回归指标\t|准确率、F1 分数、AUC 等分类指标|\n",
    "|参数 class_weight\t|不常用（回归任务通常不需要）\t|常用（处理类别不平衡）|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599f969-f4d9-4ed7-a799-ae163625ffa0",
   "metadata": {},
   "source": [
    "## 示例代码：使用 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656bfe11-7624-4e21-b58e-070b17da4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集 MSE: 754.6877\n",
      "测试集 R² 分数: 0.8206\n",
      "树的深度: 5\n",
      "叶子节点数: 28\n",
      "\n",
      "特征重要性排序:\n",
      "Feature 0: 0.8011\n",
      "Feature 3: 0.1913\n",
      "Feature 9: 0.0036\n",
      "Feature 4: 0.0031\n",
      "Feature 6: 0.0009\n",
      "Feature 8: 0.0000\n",
      "Feature 5: 0.0000\n",
      "Feature 7: 0.0000\n",
      "Feature 2: 0.0000\n",
      "Feature 1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 生成回归数据集\n",
    "X, y = make_regression(\n",
    "    n_samples=1000, n_features=10, n_informative=5, noise=10, random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化并训练模型\n",
    "model = DecisionTreeRegressor(\n",
    "    max_depth=5,                # 限制树深，防止过拟合\n",
    "    min_samples_leaf=10,        # 每个叶子节点至少10个样本\n",
    "    criterion='friedman_mse',            # 使用均方误差作为分裂标准\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 预测与评估\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"测试集 MSE: {mse:.4f}\")\n",
    "print(f\"测试集 R² 分数: {r2:.4f}\")\n",
    "print(f\"树的深度: {model.get_depth()}\")\n",
    "print(f\"叶子节点数: {model.get_n_leaves()}\")\n",
    "\n",
    "# 查看特征重要性\n",
    "importances = model.feature_importances_\n",
    "feature_names = [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# 排序并打印特征重要性\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"\\n特征重要性排序:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{feature_names[indices[f]]}: {importances[indices[f]]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
