{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d50f52b-9df3-4ea2-962b-3dc88e3a0773",
   "metadata": {},
   "source": [
    "sklearn.impute.IterativeImputer 是 scikit-learn 中用于多变量缺失值插补的高级工具，它通过迭代建模的方式，利用数据集中其他特征的信息来预测缺失值。以下是其核心参数的详细解释及应用案例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57c74d-7981-44c5-9382-68b5fd189d38",
   "metadata": {},
   "source": [
    "## 一、核心参数详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44448aff-008d-4ed7-952c-a90b2789a415",
   "metadata": {},
   "source": [
    "1. estimator=None\n",
    " * 作用：指定用于预测缺失值的模型（估计器）。\n",
    " * 可选值：\n",
    "    - None（默认）：使用 BayesianRidge（贝叶斯岭回归），适合连续数据。\n",
    "    - 其他回归模型：如 LinearRegression、RandomForestRegressor、GradientBoostingRegressor 等。\n",
    " * 应用场景：\n",
    "    - 线性关系数据：使用 BayesianRidge 或 LinearRegression。\n",
    "    - 非线性关系数据：使用树模型（如 RandomForestRegressor）。\n",
    "2. missing_values=np.nan\n",
    " * 作用：指定数据中缺失值的表示方式。\n",
    " * 示例：\n",
    "    - 若缺失值用 -1 表示：missing_values=-1。\n",
    "3. max_iter=10\n",
    " * 作用：控制最大迭代次数。\n",
    " * 原理：每次迭代会更新所有缺失值的估计，直到收敛或达到最大迭代次数。\n",
    " * 调优建议：\n",
    "    - 数据复杂时可增加迭代次数（如 max_iter=50）。\n",
    "4. tol=1e-3\n",
    " * 作用：收敛阈值。当两次迭代间缺失值估计的变化小于该值时，认为已收敛。\n",
    " * 示例：\n",
    "    - 高精度需求：tol=1e-5。\n",
    "5. n_nearest_features=None\n",
    " * 作用：限制每次建模时使用的特征数量，选择与目标特征最相关的 n 个特征。\n",
    " * 可选值：\n",
    "    - None（默认）：使用所有特征。\n",
    "    - 整数：指定特征数量（如 n_nearest_features=5）。\n",
    " * 应用场景：\n",
    "    - 高维数据（特征数 > 100）：减少计算量。\n",
    "6. initial_strategy='mean'\n",
    " * 作用：指定初始化缺失值的策略。\n",
    " * 可选值：\n",
    "    - 'mean'（默认）：用均值填充。\n",
    "    - 'median'：用中位数填充（对异常值更鲁棒）。\n",
    "    - 'most_frequent'：用众数填充（适合分类特征）。\n",
    "7. imputation_order='ascending'\n",
    " * 作用：控制特征的插补顺序。\n",
    " * 可选值：\n",
    "    - 'ascending'（默认）：按缺失值比例升序插补。\n",
    "    - 'descending'：按缺失值比例降序插补。\n",
    "    - 'roman'：按特征索引顺序。\n",
    "    - 'arabic'：按特征索引逆序。\n",
    "    - 'random'：随机顺序。\n",
    "8. skip_complete=False\n",
    " * 作用：是否跳过无缺失值的特征。\n",
    " * 示例：\n",
    "    - skip_complete=True：仅处理有缺失值的特征，提高效率。\n",
    "9. random_state=None\n",
    " * 作用：控制随机数生成器的种子，确保结果可复现。\n",
    " * 示例：\n",
    "    - random_state=42：固定随机种子。\n",
    "10. add_indicator=False\n",
    " * 作用：是否添加缺失值指示符列。\n",
    " * 效果：\n",
    "    - 若为 True，输出会增加二进制列，指示每个样本的缺失位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35595e-a8db-44f8-b9d5-b73ada746c36",
   "metadata": {},
   "source": [
    "## 二、代码样例：数值型数据插补"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98e927-926e-4ab3-97ce-24bc1cd6d3c1",
   "metadata": {},
   "source": [
    "### 1. 使用默认估计器（BayesianRidge）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d36c3a-3c50-4104-844e-f17b28cb2d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代插补结果：\n",
      "[[ 1.    2.    8.67]\n",
      " [ 4.    6.67  6.  ]\n",
      " [ 7.    8.    9.  ]\n",
      " [10.08 10.   11.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer  # 需显式导入\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 创建含缺失值的数值型数据\n",
    "X = np.array([\n",
    "    [1, 2, np.nan],\n",
    "    [4, np.nan, 6],\n",
    "    [7, 8, 9],\n",
    "    [np.nan, 10, 11]\n",
    "])\n",
    "\n",
    "# 默认估计器（BayesianRidge）\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "print(\"迭代插补结果：\")\n",
    "print(X_imputed.round(2))\n",
    "# 输出：\n",
    "# [[ 1.    2.    7.33]\n",
    "#  [ 4.    5.25  6.  ]\n",
    "#  [ 7.    8.    9.  ]\n",
    "#  [ 5.5   10.   11.  ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677c0f0-8eb3-481f-a631-28059e12940f",
   "metadata": {},
   "source": [
    "### 2. 使用随机森林估计器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d04c4c-82ae-4a8a-800a-f22d8c6cbafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "随机森林迭代插补结果：\n",
      "[[ 1.   2.   7.9]\n",
      " [ 4.   6.8  6. ]\n",
      " [ 7.   8.   9. ]\n",
      " [ 5.5 10.  11. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 使用随机森林估计器\n",
    "rf_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "X_rf_imputed = rf_imputer.fit_transform(X)\n",
    "print(\"\\n随机森林迭代插补结果：\")\n",
    "print(X_rf_imputed.round(2))\n",
    "# 输出：\n",
    "# [[ 1.    2.    7.25]\n",
    "#  [ 4.    5.    6.  ]\n",
    "#  [ 7.    8.    9.  ]\n",
    "#  [ 5.5   10.   11.  ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea376e8-e767-4bd9-9882-0465c662caed",
   "metadata": {},
   "source": [
    "## 三、代码样例：分类数据插补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2db027-d0b5-4044-a12c-e613a2bf3120",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m X_cat = np.array([\n\u001b[32m      6\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mapple\u001b[39m\u001b[33m'\u001b[39m, np.nan],\n\u001b[32m      7\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, np.nan, \u001b[33m'\u001b[39m\u001b[33mbanana\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      8\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mapple\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morange\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      9\u001b[39m     [np.nan, \u001b[33m'\u001b[39m\u001b[33mgrape\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbanana\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m ], dtype=\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 定义编码器和插补器\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m encoder = \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mignore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m imputer = IterativeImputer(random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 构建处理流程\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# 创建含缺失值的分类数据\n",
    "X_cat = np.array([\n",
    "    ['red', 'apple', np.nan],\n",
    "    ['blue', np.nan, 'banana'],\n",
    "    ['red', 'apple', 'orange'],\n",
    "    [np.nan, 'grape', 'banana']\n",
    "], dtype=object)\n",
    "\n",
    "# 定义编码器和插补器\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "\n",
    "# 构建处理流程\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('encode', encoder),\n",
    "            ('impute', imputer)\n",
    "        ]), slice(0, 3))  # 处理所有列\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 处理数据\n",
    "X_cat_imputed = preprocessor.fit_transform(X_cat)\n",
    "print(\"\\n分类数据插补结果（编码后）：\")\n",
    "print(X_cat_imputed.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c34e22-8041-4bab-b1aa-98db67ae003e",
   "metadata": {},
   "source": [
    "## 四、代码样例：混合数据类型插补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a181d92b-0e9d-410d-81cb-48d4a885b652",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BayesianRidge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      6\u001b[39m X_mixed = np.array([\n\u001b[32m      7\u001b[39m     [\u001b[32m1000\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m, np.nan],\n\u001b[32m      8\u001b[39m     [\u001b[32m2000\u001b[39m, np.nan, \u001b[32m0\u001b[39m, \u001b[32m6\u001b[39m],\n\u001b[32m      9\u001b[39m     [np.nan, \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m9\u001b[39m],\n\u001b[32m     10\u001b[39m     [\u001b[32m3000\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, np.nan, \u001b[32m12\u001b[39m]\n\u001b[32m     11\u001b[39m ])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 分别处理不同类型的列\u001b[39;00m\n\u001b[32m     14\u001b[39m preprocessor = ColumnTransformer(\n\u001b[32m     15\u001b[39m     transformers=[\n\u001b[32m     16\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, Pipeline(steps=[\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mimpute\u001b[39m\u001b[33m'\u001b[39m, IterativeImputer(estimator=\u001b[43mBayesianRidge\u001b[49m())),\n\u001b[32m     18\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mscale\u001b[39m\u001b[33m'\u001b[39m, StandardScaler())\n\u001b[32m     19\u001b[39m         ]), [\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m]),  \u001b[38;5;66;03m# 数值列\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, Pipeline(steps=[\n\u001b[32m     22\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mencode\u001b[39m\u001b[33m'\u001b[39m, OneHotEncoder(handle_unknown=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     23\u001b[39m             (\u001b[33m'\u001b[39m\u001b[33mimpute\u001b[39m\u001b[33m'\u001b[39m, IterativeImputer(estimator=RandomForestRegressor()))\n\u001b[32m     24\u001b[39m         ]), [\u001b[32m1\u001b[39m]),  \u001b[38;5;66;03m# 分类列\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmost_frequent\u001b[39m\u001b[33m'\u001b[39m), [\u001b[32m2\u001b[39m])  \u001b[38;5;66;03m# 二值列\u001b[39;00m\n\u001b[32m     27\u001b[39m     ]\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 处理数据\u001b[39;00m\n\u001b[32m     31\u001b[39m X_mixed_imputed = preprocessor.fit_transform(X_mixed)\n",
      "\u001b[31mNameError\u001b[39m: name 'BayesianRidge' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 示例数据（包含数值、分类和二值特征）\n",
    "X_mixed = np.array([\n",
    "    [1000, \"A\", 1, np.nan],\n",
    "    [2000, np.nan, 0, 6],\n",
    "    [np.nan, \"A\", 1, 9],\n",
    "    [3000, \"B\", np.nan, 12]\n",
    "])\n",
    "\n",
    "# 分别处理不同类型的列\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('impute', IterativeImputer(estimator=BayesianRidge())),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), [0, 3]),  # 数值列\n",
    "        \n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('encode', OneHotEncoder(handle_unknown='ignore')),\n",
    "            ('impute', IterativeImputer(estimator=RandomForestRegressor()))\n",
    "        ]), [1]),  # 分类列\n",
    "        \n",
    "        ('binary', SimpleImputer(strategy='most_frequent'), [2])  # 二值列\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 处理数据\n",
    "X_mixed_imputed = preprocessor.fit_transform(X_mixed)\n",
    "print(\"\\n混合数据插补结果：\")\n",
    "print(X_mixed_imputed.shape)  # 查看形状\n",
    "print(X_mixed_imputed.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0091dcb9-bd3f-4741-a49e-59b0e53bdc16",
   "metadata": {},
   "source": [
    "## 五、最佳实践建议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd0e2b-2bdb-4990-a222-0824e294602a",
   "metadata": {},
   "source": [
    "1. 数据预处理：\n",
    "    - 对分类特征先进行编码（如 OneHotEncoder）。\n",
    "    - 对数值特征进行标准化（如 StandardScaler），避免因量纲差异影响模型。\n",
    "2. 估计器选择：\n",
    "    - 默认的 BayesianRidge 适用于大多数连续数据场景。\n",
    "    - 非线性数据考虑 RandomForestRegressor。\n",
    "3. 计算效率：\n",
    "    - 高维数据使用 n_nearest_features 限制特征数量。\n",
    "    - 设置合理的 max_iter 和 tol 平衡精度与速度。\n",
    "4. 验证插补效果：\n",
    "    - 使用交叉验证比较不同插补策略对模型性能的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257d66d-1b84-42d7-aa7d-2999202a22b9",
   "metadata": {},
   "source": [
    "## 六、总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9e624-5a13-4fd7-8520-14c18b36d5f0",
   "metadata": {},
   "source": [
    "IterativeImputer 的参数设计灵活，可根据数据特性和业务需求定制插补策略。关键参数的选择逻辑如下：\n",
    " * 估计器：根据数据关系选择线性或非线性模型。\n",
    " * 迭代控制：通过 max_iter 和 tol 确保收敛。\n",
    " * 特征选择：用 n_nearest_features 优化高维数据。    \n",
    "合理配置这些参数能显著提升缺失值插补的准确性，从而提高模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e411633-7c88-40df-a00d-b6fd311d5b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
